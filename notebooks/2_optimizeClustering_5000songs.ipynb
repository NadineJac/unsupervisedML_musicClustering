{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcead12",
   "metadata": {},
   "source": [
    "# Optimize clustering into playlists with 5000 songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90795c",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab24376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This will ensure the outputs of the .transform() method are pandas data frames\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"../data/3_spotify_5000_songs.csv\")\n",
    "songs.columns = songs.columns.str.strip()\n",
    "songs = songs.set_index([\"name\", \"artist\"])\n",
    "songs_df = songs.drop(columns=[\"id\", \"html\",  \"type\", \"Unnamed: 0\"])\n",
    "#\"time_signature\", \"duration_ms\",\"tempo\", \"mode\", \"key\", \"loudness\",\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aca80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix on the numeric columns\n",
    "corr = songs_df.select_dtypes('number').corr()\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr,cmap=\"vlag\", annot=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193186d",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978845a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e274a2",
   "metadata": {},
   "source": [
    "---\n",
    "# Try various scaling and transformation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60acd8",
   "metadata": {},
   "source": [
    "Try out the different scalers and transformers on the Spotify data and compare the results. Which scaler do you feel had the greatest impact? And, maybe, which scaler didn't help at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_distances = pd.DataFrame(pairwise_distances(songs_df),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731832c",
   "metadata": {},
   "source": [
    "## Min Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50beae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "songs_minmax = scaler.fit_transform(songs_df) # in one step, could also be done seperatly\n",
    "songs_minmax_distances = pd.DataFrame(pairwise_distances(songs_minmax),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fd34a",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03808ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "songs_standard = scaler.fit_transform(songs_df)\n",
    "songs_standard_distances = pd.DataFrame(pairwise_distances(songs_standard),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed3bee",
   "metadata": {},
   "source": [
    "## Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "songs_robust = scaler.fit_transform(songs_df)\n",
    "songs_robust_distances = pd.DataFrame(pairwise_distances(songs_robust),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01828c",
   "metadata": {},
   "source": [
    "## Quantile Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QuantileTransformer object\n",
    "scaler = QuantileTransformer()\n",
    "songs_quantile = scaler.fit_transform(songs_df)\n",
    "songs_quantile_distances = pd.DataFrame(pairwise_distances(songs_quantile),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0e044",
   "metadata": {},
   "source": [
    "## Power transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67582386",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = PowerTransformer()\n",
    "songs_power = scaler.fit_transform(songs_df)\n",
    "songs_power_distances = pd.DataFrame(pairwise_distances(songs_power),\n",
    "                                        index=songs_df.index,\n",
    "                                        columns=songs_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab5d0b",
   "metadata": {},
   "source": [
    "## Plot all scalings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2130504",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "column_name = 'tempo'\n",
    "# choose feature here\n",
    "fig, ax = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "sns.histplot(data=songs_df.loc[:,column_name], bins=10, kde=True, ax=ax[0, 0]);\n",
    "sns.histplot(data=songs_minmax.loc[:,column_name], bins=10, kde=True, ax=ax[0, 1]);\n",
    "sns.histplot(data=songs_standard.loc[:,column_name], bins=10, kde=True, ax=ax[1, 1]);\n",
    "sns.histplot(data=songs_robust.loc[:,column_name], bins=10, kde=True, ax=ax[1, 0]);\n",
    "sns.histplot(data=songs_quantile.loc[:,column_name], bins=12, kde=True, ax=ax[2, 0]);\n",
    "sns.histplot(data=songs_power.loc[:,column_name], bins=10, kde=True, ax=ax[2, 1]);\n",
    "\n",
    "ax[0, 0].set_title(f'Distribution of {column_name} without scaling')\n",
    "ax[0, 1].set_title(f'Distribution of {column_name} with MinMax scaling')\n",
    "ax[1, 0].set_title(f'Distribution of {column_name} with Robust scaling')\n",
    "ax[1, 1].set_title(f'Distribution of {column_name} with Standard scaling')\n",
    "ax[2, 0].set_title(f'Distribution of {column_name} with Quantile transforming')\n",
    "ax[2, 1].set_title(f'Distribution of {column_name} with Power transforming')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmans (only do with 10 sampled songs)\n",
    "import random\n",
    "\n",
    "samples = random.sample(range(0, 5001), 10)\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 20))\n",
    "\n",
    "sns.heatmap(songs_distances.iloc[samples, samples], ax=ax[0, 0], linewidths=.2);\n",
    "sns.heatmap(songs_minmax_distances.iloc[samples, samples], ax=ax[0, 1], linewidths=.2);\n",
    "sns.heatmap(songs_robust_distances.iloc[samples, samples], ax=ax[1, 0], linewidths=.2);\n",
    "sns.heatmap(songs_standard_distances.iloc[samples, samples], ax=ax[1, 1], linewidths=.2);\n",
    "sns.heatmap(songs_quantile_distances.iloc[samples, samples], ax=ax[2, 0], linewidths=.2);\n",
    "sns.heatmap(songs_power_distances.iloc[samples, samples], ax=ax[2, 1], linewidths=.2);\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n",
    "ax[0, 0].set_title('NOT in the same 1-10 scaling')\n",
    "ax[0, 1].set_title('MinMax scaled')\n",
    "ax[1, 0].set_title('Robust scaled')\n",
    "ax[1, 1].set_title('Standard scaled')\n",
    "ax[2, 0].set_title('Quantile transformed')\n",
    "ax[2, 1].set_title('Power transformed');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9b93a",
   "metadata": {},
   "source": [
    "---\n",
    "# Try numbers of clusters\n",
    "Each playlist should have between 50 and 250 songs. For a dataset with roughly 5000 songs, that means between 20 and 100 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaled_audio_features = songs_minmax.copy()\n",
    "inertia_list = []\n",
    "n_cluster_list = []\n",
    "silhouette_list = []\n",
    "songs_Labels_list = []\n",
    "cluster_centers_list = []\n",
    "min_count = []\n",
    "max_count = []\n",
    "mean_count = []\n",
    "\n",
    "max_k = 100\n",
    "for i in range(2,max_k+1 ):\n",
    "    myKMeans = KMeans(n_clusters=i)\n",
    "    myKMeans.fit(scaled_audio_features)\n",
    "    n_cluster_list.append(i)\n",
    "    inertia_list.append(round(myKMeans.inertia_))\n",
    "    silhouette_list.append(silhouette_score(scaled_audio_features, myKMeans.labels_)) # not yet working, all values zero! Check-up\n",
    "    unique, counts = np.unique(myKMeans.labels_, return_counts=True)\n",
    "\n",
    "    # Compute statistics\n",
    "    min_count.append(counts.min())\n",
    "    max_count.append(counts.max())\n",
    "    mean_count.append(counts.mean())\n",
    "    songs_Labels_list.append(myKMeans.labels_)\n",
    "    cluster_centers_list.append(myKMeans.cluster_centers_)\n",
    "\n",
    "clusters_df = pd.DataFrame({'n_clusters':n_cluster_list, \n",
    "                            'inertia':inertia_list, \n",
    "                            'silhouette':silhouette_list, \n",
    "                            'min':min_count,\n",
    "                            'max':max_count,\n",
    "                            'mean':mean_count,\n",
    "                            'labels':songs_Labels_list,\n",
    "                            'centroids':cluster_centers_list})\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d379929",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.plot(x='n_clusters', y='inertia');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ee583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from example with sns\n",
    "# Set the Seaborn theme to darkgrid\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "(\n",
    "# Create a line plot of the inertia scores\n",
    "sns.relplot(data=clusters_df,\n",
    "            y = 'inertia',\n",
    "            x = 'n_clusters',\n",
    "            kind = 'line',\n",
    "            marker = 'o',\n",
    "            height = 8,\n",
    "            aspect = 2)\n",
    "# Set the title of the plot\n",
    ".set(title=f\"Inertia score from 2 to {max_k} clusters\")\n",
    "# Set the axis labels\n",
    ".set_axis_labels(\"Number of clusters\", \"Inertia score\")\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.plot(x='n_clusters', y='silhouette');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg number of songs/playlist, as well as min/max\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "(\n",
    "# Create a line plot of the inertia scores\n",
    "sns.relplot(data=clusters_df,\n",
    "            y = 'in',\n",
    "            x = 'n_clusters',\n",
    "            kind = 'line',\n",
    "            marker = 'o',\n",
    "            height = 8,\n",
    "            aspect = 2)\n",
    "# Set the title of the plot\n",
    ".set(title=f\"NUmber of songsper playlist from 2 to {max_k} clusters\")\n",
    "# Set the axis labels\n",
    ".set_axis_labels(\"Number of clusters\", \"Inertia score\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d67aec",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluate Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the cluster output to our original DataFrame\n",
    "scaled_features_df[\"cluster\"] = clusters\n",
    "scaled_features_df.groupby(by=\"cluster\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f78f2a",
   "metadata": {},
   "source": [
    "---\n",
    "# Suggestions beyond the algorithm\n",
    "* include songs liked by user\n",
    "* include popular songs\n",
    "* -> songs could be in more than one playlist\n",
    "* include curated lists!!!\n",
    "Either spotify API or kaggle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caf50c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
